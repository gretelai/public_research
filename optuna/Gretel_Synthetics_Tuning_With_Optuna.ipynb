{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142b1546",
   "metadata": {},
   "source": [
    "# Gretel Synthetics Tuning With Optuna\n",
    "* This notebook will let you tune the Gretel synthetic model hyperparameters of several datasets at once.\n",
    "* It is also setup to run multiple Optuna trials at once using an SQLite database (prepackaged with most operating systems).\n",
    "* This notebook makes use of our python module Optuna_Trials.py. In most cases, you won't need to modify this module. It is configured with all the relelvant synyhetic model hyperparameters and their relevant ranges. If you'd like to change which parameters are tuned or the range of values to tune over, then you will need to modify that module.\n",
    "* This notebook works seemlessly on Linux and Ubuntu, but not on a Mac."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a886ca",
   "metadata": {},
   "source": [
    "## First specify all the options needed in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf3fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First you'll need to specify the location of a file that contains a list of all the datasets (e.g. training \n",
    "# filenames) you'd like to tune synthetic models on. Here we use a list containing eight popular Kaggle datasets\n",
    "\n",
    "dataset_list = \"datasets/dataset_list.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you'll need to specify how many processes you'd like to run in parallel for each dataset. As we also process\n",
    "# datasets in parallel, the total number of processes running in parallel with be dataset cnt x trial_job_cnt;\n",
    "# which in this case sums up to 48. Note, each process has very low CPU impact as we will be using Gretel SDK\n",
    "# calls to the cloud to train each model.\n",
    "\n",
    "trial_job_cnt = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ea0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you'll need to specify how many trials (e.g. set of hyperparameters to test out) you'd like each process\n",
    "# to run. Here we're setting trials_per_job to 5 which means the overall number of trials per dataset will be 30.\n",
    "# This is typically a good set of trials for Optuna to narrow in on an optimal hyperparameter set.\n",
    "\n",
    "trials_per_job = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3109bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now set a base name you'd like to use for each study. There will be a total of eight studies, since we have\n",
    "# eight datasets. Later, we'll set each study name to the base name you've chosen followed by the dataset number.\n",
    "\n",
    "study_base_name = \"Optuna_Tuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you'll need to specify the database location where your trials will be stored. This will enable the running\n",
    "# of trials in the same study in parallel. Here we're using SQLite as it comes preinstalled with most operating \n",
    "# systems. If the database name you specify doesn't already exist, Optuna will create it for you.\n",
    "\n",
    "storage = \"sqlite:///tuning.db\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now specify the optimization algorithm you'd like Optuna to use. Here, we're choosing the default optimizer TPE\n",
    "# (Tree-structured Parzen Estimator) algorithm. If you're just starting out, a good rule of thumb is if you have \n",
    "# a lot of computing resources, use Random Search, otherwise use TPE. You can read more about Optuna sampling\n",
    "# algorithms here:\n",
    "# https://optuna.readthedocs.io/en/stable/tutorial/10_key_features/003_efficient_optimization_algorithms.html#sphx-glr-tutorial-10-key-features-003-efficient-optimization-algorithms-py\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "sampler=TPESampler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d2503",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec591d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U gretel-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21fd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Optuna\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c578b05",
   "metadata": {},
   "source": [
    "## Specify your Gretel API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e25c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "api_key=getpass(prompt=\"Enter Gretel API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a318922",
   "metadata": {},
   "source": [
    "## Load the plethora of visualization options available in Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc600a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_contour\n",
    "from optuna.visualization import plot_edf\n",
    "from optuna.visualization import plot_intermediate_values\n",
    "from optuna.visualization import plot_optimization_history\n",
    "from optuna.visualization import plot_parallel_coordinate\n",
    "from optuna.visualization import plot_param_importances\n",
    "from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1777374",
   "metadata": {},
   "source": [
    "## Grab the default Synthetic Config file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smart_open import open\n",
    "import yaml\n",
    "\n",
    "with open(\"https://raw.githubusercontent.com/gretelai/gretel-blueprints/main/config_templates/gretel/synthetics/default.yml\", 'r') as stream:\n",
    "    config = yaml.safe_load(stream) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa997c7",
   "metadata": {},
   "source": [
    "## Define our function that will initiate an Optuna study\n",
    "* This function uses Optuna's engueue_trial method to queue up Gretel synthetics default set of model hyperparameters. This is a good spot for Optuna to begin. You can use this method to queue up as many parameter settings as you'd like. Optuna will first try the hyperparameter sets you've queued up and then move on to using it's optimization algorithm to search for other potential sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bea18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import optuna\n",
    "\n",
    "def create_study(study_name, dataset, trial_job_cnt, trials_per_job, api_key, storage, sampler):\n",
    "       \n",
    "    study = optuna.create_study(study_name=study_name,storage=storage, sampler=sampler, direction=\"maximize\")\n",
    "    \n",
    "    # Tell Optuna to start with our default config settings. This will be your Trial 0\n",
    "\n",
    "    study.enqueue_trial(\n",
    "        {\n",
    "        \"vocab_size\": config['models'][0]['synthetics']['params']['vocab_size'],\n",
    "        \"reset_states\": config['models'][0]['synthetics']['params']['reset_states'],\n",
    "        \"rnn_units\": config['models'][0]['synthetics']['params']['rnn_units'],\n",
    "        \"learning_rate\": config['models'][0]['synthetics']['params']['learning_rate'],\n",
    "        \"gen_temp\": config['models'][0]['synthetics']['params']['gen_temp'],\n",
    "        \"dropout_rate\": config['models'][0]['synthetics']['params']['dropout_rate'],\n",
    "        }\n",
    "    )\n",
    "      \n",
    "    # Now initiate \"trial_job_cnt\" processes for this study, each running \"trials_per_job\" trials\n",
    "    \n",
    "    trial_cnt = str(trials_per_job)\n",
    "    for i in range(trial_job_cnt):\n",
    "        mytrial = subprocess.Popen([\"python\", \"src/Optuna_Trials.py\", study_name, trial_cnt, dataset, api_key, storage])\n",
    "    \n",
    "    return study\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aadbe9",
   "metadata": {},
   "source": [
    "## Read in your datasets and start tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506be97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets = pd.read_csv(dataset_list)\n",
    "\n",
    "studies = []\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    dataset = datasets.loc[i][\"filename\"]\n",
    "    study_name = study_base_name + str(i)\n",
    "    studies.append(create_study(study_name, dataset, trial_job_cnt, trials_per_job, api_key, storage, sampler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f530825",
   "metadata": {},
   "source": [
    "## Monitor your tuning as it progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec6851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Track each trial's status and SQS scores as they complete\n",
    "\n",
    "for i in range(len(studies)):\n",
    "    study = studies[i]\n",
    "    print(\"Study \" + str(i))\n",
    "    for j in range(len(study.trials)):\n",
    "        state = str(study.trials[j].state)[11:]\n",
    "        if state == \"COMPLETE\":\n",
    "            sqs = study.trials[j].values[0]\n",
    "            print(\"\\tTrial \" + str(j) + \" has state \" + state + \" and SQS \" + str(sqs))\n",
    "        else:\n",
    "            print(\"\\tTrial \" + str(j) + \" has state \" + state)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f24813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can look graphically at the optimization history of a study while waiting for it to complete.\n",
    "\n",
    "study = studies[0]\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8fed8",
   "metadata": {},
   "source": [
    "## Analyze your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55039d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When your trials are complete, you can use this cell to gather all results into a dataframe.\n",
    "# Remember: trial 0 is the Gretel synthetic default config.\n",
    "\n",
    "study_list = []\n",
    "trial_list = []\n",
    "best_list = []\n",
    "state_list = []\n",
    "sqs_list = []\n",
    "vocab_list = []\n",
    "rnn_list = []\n",
    "dropout_list = []\n",
    "gentemp_list = []\n",
    "learning_list = []\n",
    "reset_list = []\n",
    "dataset_list = []\n",
    "\n",
    "# Loop through each study (dataset)\n",
    "for i in range(len(studies)):\n",
    "    study = studies[i]\n",
    "    best_trial = study.best_trial.number\n",
    "    dataset = datasets.loc[i][\"filename\"]\n",
    "    \n",
    "    # Loop through each trial in the study\n",
    "    for j in range(len(study.trials)):\n",
    "        best = False\n",
    "        if j == best_trial:\n",
    "            best = True\n",
    "        state = str(study.trials[j].state)[11:]\n",
    "        values = study.trials[j].values\n",
    "        sqs = 0\n",
    "        if values:\n",
    "            sqs = values[0]\n",
    "        vocab_size = study.trials[j].params['vocab_size']\n",
    "        rnn_units = study.trials[j].params['rnn_units']\n",
    "        dropout_rate = round(study.trials[j].params['dropout_rate'], 4)\n",
    "        gen_temp = round(study.trials[j].params['gen_temp'], 4)\n",
    "        learning_rate = round(study.trials[j].params['learning_rate'], 4)\n",
    "        reset_states = study.trials[j].params['reset_states']\n",
    "        study_list.append(i)\n",
    "        trial_list.append(j)\n",
    "        best_list.append(best)\n",
    "        state_list.append(state)\n",
    "        sqs_list.append(sqs)\n",
    "        vocab_list.append(vocab_size)\n",
    "        rnn_list.append(rnn_units)\n",
    "        dropout_list.append(dropout_rate)\n",
    "        gentemp_list.append(gen_temp)\n",
    "        learning_list.append(learning_rate)\n",
    "        reset_list.append(reset_states)\n",
    "        dataset_list.append(dataset)\n",
    "       \n",
    "# Gather all results into a datafame\n",
    "df_results_studies = pd.DataFrame({\"study\": study_list, \"trial\": trial_list, \"best\": best_list, \"state\": state_list,\n",
    "                          \"sqs\": sqs_list, \"vocab_size\": vocab_list, \"rnn_units\": rnn_list, \"dropout_rate\": dropout_list,\n",
    "                          \"gen_temp\": gentemp_list, \"learning_rate\": learning_list, \"reset_states\": reset_list,\n",
    "                          \"dataset\": dataset_list})\n",
    "\n",
    "# Show trial state counts for each study. Note, it's typical to have a few Optuna errors.\n",
    "df_results_studies.groupby(['study', 'state']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e7092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just look at the best run for each study (e.g. dataset)\n",
    "df_results_studies[df_results_studies[\"best\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa8df27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top scoring runs for a specific study\n",
    "df_results_studies[df_results_studies[\"study\"] == 1].sort_values(by='sqs', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1330445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the parameter importance for a specific study\n",
    "study = studies[0]\n",
    "plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the parameter relationship as slice plot in a study.\n",
    "# This shows the trial number as the color, so you can see the tuning homing in on a range\n",
    "\n",
    "study = studies[0]\n",
    "plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the contour plot to look at the relationship between parameters and the objective value\n",
    "\n",
    "study = studies[0]\n",
    "plot_contour(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parallel coordinates map can be insightful. Each line is a trial\n",
    "# Note, because I made vocab_size categorical in Optuna, they aren't in the right order\n",
    "\n",
    "study = studies[0]\n",
    "plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The params field is optional but useful if you want to see two params side by side\n",
    "\n",
    "study = studies[0]\n",
    "plot_parallel_coordinate(study, params=[\"rnn_units\", \"dropout_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb106c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a study's Empirical Distribution Function Plot\n",
    "\n",
    "study = studies[0]\n",
    "plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efd388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's how you look at the nitty gritty of what comes back from Optuna\n",
    "\n",
    "study = studies[0]\n",
    "study.get_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick way to get a study's best trial\n",
    "study.best_trial.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a specific trial's state\n",
    "study.trials[5].state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a specific study's params\n",
    "study.trials[20].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a specific study's SQS (Optimization funtion) value (note it's a list)\n",
    "study.trials[20].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf4d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of how to access a trial's params\n",
    "study.trials[0].params['vocab_size']\n",
    "study.trials[0].params['rnn_units']\n",
    "study.trials[0].params['dropout_rate']\n",
    "study.trials[0].params['gen_temp']\n",
    "study.trials[0].params['learning_rate']\n",
    "study.trials[0].params['reset_states']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example of how you would delete a trial if you ever need to,\n",
    "# But don't do this until you're fully done analyzing it.\n",
    "\n",
    "optuna.delete_study(study_name=\"Optuna_Tuning0\", storage=storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14631bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
